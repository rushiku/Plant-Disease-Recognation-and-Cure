{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5f08cde-a7c5-4870-a2a7-339f840eb428",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.layers import Rescaling, RandomFlip, RandomRotation, RandomZoom\n",
    "import os\n",
    "# from PIL import Image\n",
    "# import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01097627-c0d4-4a14-8f79-f22415c332df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def remove_corrupted_images(directory):\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            try:\n",
    "                img_path = os.path.join(root, file)\n",
    "                img = Image.open(img_path)\n",
    "                img.verify()  # Verify the file\n",
    "            except (IOError, SyntaxError):\n",
    "                print(f\"Removing corrupted image: {img_path}\")\n",
    "                os.remove(img_path)\n",
    "\n",
    "remove_corrupted_images('train')\n",
    "remove_corrupted_images('valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7f911e2-9e9f-4353-aa19-9710ce56e95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from PIL import Image\n",
    "\n",
    "def reencode_images(directory):\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.jpg', '.jpeg')):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with Image.open(file_path) as img:\n",
    "                        img = img.convert(\"RGB\")\n",
    "                        img.save(file_path, \"JPEG\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error re-encoding {file_path}: {e}\")\n",
    "\n",
    "# Run for both training and validation datasets\n",
    "reencode_images(\"train\")\n",
    "reencode_images(\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eef422cd-04da-4672-9af5-bd06b460d43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd439482-588a-4221-b77f-dbe858a36e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU'))) #Checking for GPU connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f425ccb0-eee6-4f06-89c9-a4623aaa483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "    tf.keras.layers.RandomZoom(0.2),\n",
    "    tf.keras.layers.RandomContrast(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2caf9f9b-cdc7-4dc9-9ad5-32b226168b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 139119 files belonging to 109 classes.\n"
     ]
    }
   ],
   "source": [
    "#Training Image preprocessing\n",
    "\n",
    "training_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    'train',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    ").map(lambda x, y: (tf.keras.layers.Rescaling(1./255)(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7f40485-8809-41a5-b7f7-390280449743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43834 files belonging to 109 classes.\n"
     ]
    }
   ],
   "source": [
    "#Validation Image Preprocessing\n",
    "\n",
    "validation_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    'valid',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    ").map(lambda x, y: (tf.keras.layers.Rescaling(1./255)(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f40abb-d560-44a3-841d-71e031f9359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential([\n",
    "    # Data Augmentation Layer\n",
    "    data_augmentation,\n",
    "\n",
    "    # Block 1\n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', input_shape=[128, 128, 3]),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    # Block 2\n",
    "    tf.keras.layers.Conv2D(64, 3, padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    # Block 3\n",
    "    tf.keras.layers.Conv2D(128, 3, padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2),\n",
    "    tf.keras.layers.Dropout(0.35),\n",
    "\n",
    "    # Block 4\n",
    "    tf.keras.layers.Conv2D(256, 3, padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "\n",
    "    # Block 5\n",
    "    tf.keras.layers.Conv2D(512, 3, padding='same'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2),\n",
    "    tf.keras.layers.Dropout(0.45),\n",
    "\n",
    "    # Flattening and Fully Connected Layers\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(109, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "802d24ae-515b-4ccd-b54d-c0a2c978688c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn.add(tf.keras.layers.Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6b4e829-8c03-455d-aa97-4d1dfa416ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f95d63bf-8036-48e1-aa56-a3b1f25b9d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn.add(tf.keras.layers.Dense(units=512,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e05c2c61-04d2-4623-97ea-21ed06afc4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn.add(tf.keras.layers.Dropout(0.4)) #To avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57de8e51-058a-4b8d-b34c-8edf41bbb58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output Layer\n",
    "# cnn.add(tf.keras.layers.Dense(units=109,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82b58a78-5fa6-4747-98bc-448c52d5b8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling and Training Phase\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005, clipnorm=1.0)\n",
    "cnn.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab981f24-53b5-4664-9876-550d57686ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate Scheduler\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.5, patience=2, verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5a88f6b-594b-4a41-a04c-40c649357f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=5, restore_best_weights=True, verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df9aa81b-e652-47ba-bacd-ba154ba9af55",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bbf14c-cd0e-4660-8616-047d6741a7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97c2cf49-2c86-47e8-9713-95576a435946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #suppress TF warnings\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "# #suppress PIL warnings\n",
    "# warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"PIL\")\n",
    "\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./logs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cecbd78-0a47-413f-9e8c-a98aeb2378d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    training_history = cnn.fit(\n",
    "        x=training_set,\n",
    "        validation_data=validation_set,\n",
    "        epochs=30,\n",
    "        callbacks=[lr_scheduler, early_stopping, tensorboard_callback]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288c0f05-269d-4209-8e53-4b56d27604f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn = tf.keras.models.load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd7413a-1a68-4be6-9b25-8b6ebca1557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating Model\n",
    "#Training set Accuracy\n",
    "train_loss, train_acc = cnn.evaluate(training_set)\n",
    "print('Training accuracy:', train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e055ab-5c08-4a99-8483-59e3158daab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation set Accuracy\n",
    "val_loss, val_acc = cnn.evaluate(validation_set)\n",
    "print('Validation accuracy:', val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaf26d4-d67b-4f09-ab32-74c3830c2e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving Model\n",
    "cnn.save('trained_plant_disease_model.keras')\n",
    "print(f\"Model output shape: {cnn.output_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc17a1c-bb14-458a-86ef-2415e5a7d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history.history #Return Dictionary of history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00032806-bf66-4d94-91a4-44314ca48b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recording History in json\n",
    "import json\n",
    "with open('training_hist.json', 'w') as f:\n",
    "    json.dump(training_history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cebc6e-ba1d-4b2b-91ef-f7e696a2eb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training history keys:\", training_history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d0371e-b47e-42a9-9799-5f0a4baf3ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy Visualization\n",
    "epochs = range(1, len(training_history.history['accuracy']) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, training_history.history['accuracy'], color='red', label='Training Accuracy')\n",
    "plt.plot(epochs, training_history.history['val_accuracy'], color='blue', label='Validation Accuracy')\n",
    "plt.xlabel('Number of Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Visualization')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106346cd-8788-4dee-bcf5-653890b67388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some other metrics for model evaluation\n",
    "class_name = validation_set.class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16b763c-0bab-4e49-8339-6c006222acfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    'valid',\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    batch_size=1,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc2a6f2-72ca-472e-9f98-0758639c0c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Predictions\n",
    "y_pred = cnn.predict(test_set)\n",
    "predicted_categories = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc1c062-c190-4b72-9667-b95539349232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting True Class Labels\n",
    "true_categories = tf.concat([y for x, y in test_set], axis=0)\n",
    "Y_true = tf.argmax(true_categories, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d8ac96-7d83-45d5-998d-9d16a7cbb943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885b993f-a556-4ce2-8567-593a5a6df053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report and Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0930cb5f-f2ed-4f60-a6f4-a60b9dea07d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision Recall Fscore\n",
    "cm = confusion_matrix(Y_true, predicted_categories)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(Y_true, predicted_categories, target_names=class_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9525dd-6268-455d-adb3-5f8fe84d3d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Classification Report to a File\n",
    "with open('classification_report.txt', 'w') as f:\n",
    "    f.write(classification_report(Y_true, predicted_categories, target_names=class_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7bd71e-68e6-4f62-b416-3d37b2d1fa91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix Visualization\n",
    "plt.figure(figsize=(40, 40))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", annot_kws={\"size\": 10})\n",
    "plt.xlabel('Predicted Class', fontsize=20)\n",
    "plt.ylabel('Actual Class', fontsize=20)\n",
    "plt.title('Plant Disease Prediction Confusion Matrix', fontsize=25)\n",
    "plt.savefig('confusion_matrix.png')  # Save the confusion matrix as an image\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
